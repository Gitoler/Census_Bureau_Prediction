{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook to test and try machine learning model.\n",
    "author: Ung Van Tuan\n",
    "Date: June 29th 2023\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    fbeta_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0  age         workclass   fnlgt  education  \\\n0           0   39         State-gov   77516  Bachelors   \n1           1   50  Self-emp-not-inc   83311  Bachelors   \n2           2   38           Private  215646    HS-grad   \n3           3   53           Private  234721       11th   \n4           4   28           Private  338409  Bachelors   \n5           5   37           Private  284582    Masters   \n6           6   49           Private  160187        9th   \n7           7   52  Self-emp-not-inc  209642    HS-grad   \n8           8   31           Private   45781    Masters   \n9           9   42           Private  159449  Bachelors   \n\n          marital-status         occupation   relationship   race     sex  \\\n0          Never-married       Adm-clerical  Not-in-family  White    Male   \n1     Married-civ-spouse    Exec-managerial        Husband  White    Male   \n2               Divorced  Handlers-cleaners  Not-in-family  White    Male   \n3     Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n4     Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n5     Married-civ-spouse    Exec-managerial           Wife  White  Female   \n6  Married-spouse-absent      Other-service  Not-in-family  Black  Female   \n7     Married-civ-spouse    Exec-managerial        Husband  White    Male   \n8          Never-married     Prof-specialty  Not-in-family  White  Female   \n9     Married-civ-spouse    Exec-managerial        Husband  White    Male   \n\n   capital-gain  capital-loss  hours-per-week native-country salary  \n0          2174             0              40  United-States  <=50K  \n1             0             0              13  United-States  <=50K  \n2             0             0              40  United-States  <=50K  \n3             0             0              40  United-States  <=50K  \n4             0             0              40           Cuba  <=50K  \n5             0             0              40  United-States  <=50K  \n6             0             0              16        Jamaica  <=50K  \n7             0             0              45  United-States   >50K  \n8         14084             0              50  United-States   >50K  \n9          5178             0              40  United-States   >50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlgt</th>\n      <th>education</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>37</td>\n      <td>Private</td>\n      <td>284582</td>\n      <td>Masters</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>49</td>\n      <td>Private</td>\n      <td>160187</td>\n      <td>9th</td>\n      <td>Married-spouse-absent</td>\n      <td>Other-service</td>\n      <td>Not-in-family</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16</td>\n      <td>Jamaica</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>52</td>\n      <td>Self-emp-not-inc</td>\n      <td>209642</td>\n      <td>HS-grad</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>31</td>\n      <td>Private</td>\n      <td>45781</td>\n      <td>Masters</td>\n      <td>Never-married</td>\n      <td>Prof-specialty</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>14084</td>\n      <td>0</td>\n      <td>50</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>42</td>\n      <td>Private</td>\n      <td>159449</td>\n      <td>Bachelors</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>5178</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a dataframe\n",
    "df = pd.read_csv('data/clean_census.csv')\n",
    "# Display the ten first rows from the dataframe\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def process_data(\n",
    "        X, categorical_features=[], label=None, training=True, encoder=None, lb=None\n",
    "):\n",
    "\n",
    "    if label is not None:\n",
    "        y = X[label]\n",
    "        X = X.drop([label], axis=1)\n",
    "    else:\n",
    "        y = np.array([])\n",
    "\n",
    "    X_categorical = X[categorical_features].values\n",
    "    X_continuous = X.drop(*[categorical_features], axis=1)\n",
    "\n",
    "    if training is True:\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "        lb = LabelBinarizer()\n",
    "        X_categorical = encoder.fit_transform(X_categorical)\n",
    "        y = lb.fit_transform(y.values).ravel()\n",
    "    else:\n",
    "        X_categorical = encoder.transform(X_categorical)\n",
    "        try:\n",
    "            y = lb.fit_transform(y.values).ravel()\n",
    "        # Catch the case where y is None because we're doing inference.\n",
    "        except AttributeError as error:\n",
    "            print(\"Error occur: \", error)\n",
    "\n",
    "    X = np.concatenate([X_continuous, X_categorical], axis=1)\n",
    "    return X, y, encoder, lb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "['workclass',\n 'education',\n 'marital-status',\n 'occupation',\n 'relationship',\n 'race',\n 'sex',\n 'native-country']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the categorical feature except the column salary\n",
    "categorical_features = list(df.select_dtypes(['object', 'category']).columns)[:-1]\n",
    "\n",
    "# Show the columns\n",
    "categorical_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Split the dataset into train and tét\n",
    "train, test = train_test_split(df, shuffle=True, stratify=None, test_size=0.20, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Create the OneHotEncoder and LabelBinarizer() objects\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "binarizer = LabelBinarizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Get the metrics from the trained model\n",
    "def compute_model_metrics(y, preds):\n",
    "    fbeta = fbeta_score(y, preds, beta=1, zero_division=1)\n",
    "    precision = precision_score(y, preds, zero_division=1)\n",
    "    recall = recall_score(y, preds, zero_division=1)\n",
    "    return precision, recall, fbeta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Optional: implement hyperparameter tunning.\n",
    "def train_model(X_train, y_train, models):\n",
    "    for key in models.keys():\n",
    "        models[key].fit(X_train, y_train)\n",
    "    return models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# Get the processed train data\n",
    "X_train, y_train, encoder, lb = process_data(train, categorical_features=categorical_features, label=\"salary\", training=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Create a dictionary for different models\n",
    "models = {}\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "models['Extrat Classfier'] = ExtraTreesClassifier(n_estimators=50)\n",
    "models['Support Vector Machines'] = LinearSVC()\n",
    "models['Gradient Boosting'] = GradientBoostingClassifier(n_estimators=333, learning_rate=0.8, max_depth=5, random_state=0)\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "models['XGB Classifier'] = XGBClassifier(objective='binary:logistic', eta=0.3, max_depth= 5, eval_metric = 'aucpr')\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jumet/miniconda3/envs/cencus_env/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_models = train_model(X_train, y_train, models)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Get the result metrics into a dataframe\n",
    "def df_model_results(trained_models, X_data, y_data):\n",
    "    fbeta, precision, recall= {}, {}, {}\n",
    "    for key in trained_models.keys():\n",
    "        predictions = trained_models[key].predict(X_data)\n",
    "\n",
    "        fbeta[key] = fbeta_score(y_data, predictions, beta=1, zero_division=1)\n",
    "        precision[key] = precision_score(predictions, y_data)\n",
    "        recall[key] = recall_score(predictions, y_data)\n",
    "\n",
    "    df_model = pd.DataFrame(index=models.keys(), columns=['fbeta', 'precision', 'recall'])\n",
    "    df_model['fbeta'] = fbeta.values()\n",
    "    df_model['precision'] = precision.values()\n",
    "    df_model['recall'] = recall.values()\n",
    "\n",
    "    return df_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "                            fbeta  precision    recall\nLogistic Regression      0.381335   0.258820  0.724092\nExtrat Classfier         1.000000   1.000000  1.000000\nSupport Vector Machines  0.356181   0.241661  0.676999\nGradient Boosting        0.986041   0.979795  0.992366\nDecision Trees           1.000000   1.000000  1.000000\nRandom Forest            1.000000   1.000000  1.000000\nXGB Classifier           0.770244   0.712316  0.838430\nNaive Bayes              0.418564   0.306607  0.659310\nK-Nearest Neighbor       0.480656   0.347659  0.778456",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fbeta</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.381335</td>\n      <td>0.258820</td>\n      <td>0.724092</td>\n    </tr>\n    <tr>\n      <th>Extrat Classfier</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>Support Vector Machines</th>\n      <td>0.356181</td>\n      <td>0.241661</td>\n      <td>0.676999</td>\n    </tr>\n    <tr>\n      <th>Gradient Boosting</th>\n      <td>0.986041</td>\n      <td>0.979795</td>\n      <td>0.992366</td>\n    </tr>\n    <tr>\n      <th>Decision Trees</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>Random Forest</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>XGB Classifier</th>\n      <td>0.770244</td>\n      <td>0.712316</td>\n      <td>0.838430</td>\n    </tr>\n    <tr>\n      <th>Naive Bayes</th>\n      <td>0.418564</td>\n      <td>0.306607</td>\n      <td>0.659310</td>\n    </tr>\n    <tr>\n      <th>K-Nearest Neighbor</th>\n      <td>0.480656</td>\n      <td>0.347659</td>\n      <td>0.778456</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result of the model\n",
    "df_train_results = df_model_results(trained_models, X_train, y_train)\n",
    "df_train_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Get the test processed data\n",
    "X_test, y_test, encoder, lb = process_data(test, categorical_features=categorical_features, label=\"salary\", training=False, encoder=encoder, lb=binarizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "                            fbeta  precision    recall\nLogistic Regression      0.405901   0.283219  0.716088\nExtrat Classfier         0.648466   0.600125  0.705279\nSupport Vector Machines  0.376300   0.259513  0.684211\nGradient Boosting        0.686410   0.650655  0.726323\nDecision Trees           0.609410   0.601996  0.617008\nRandom Forest            0.688569   0.627573  0.762699\nXGB Classifier           0.720244   0.662508  0.789004\nNaive Bayes              0.436333   0.328135  0.650990\nK-Nearest Neighbor       0.349398   0.253275  0.563107",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fbeta</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.405901</td>\n      <td>0.283219</td>\n      <td>0.716088</td>\n    </tr>\n    <tr>\n      <th>Extrat Classfier</th>\n      <td>0.648466</td>\n      <td>0.600125</td>\n      <td>0.705279</td>\n    </tr>\n    <tr>\n      <th>Support Vector Machines</th>\n      <td>0.376300</td>\n      <td>0.259513</td>\n      <td>0.684211</td>\n    </tr>\n    <tr>\n      <th>Gradient Boosting</th>\n      <td>0.686410</td>\n      <td>0.650655</td>\n      <td>0.726323</td>\n    </tr>\n    <tr>\n      <th>Decision Trees</th>\n      <td>0.609410</td>\n      <td>0.601996</td>\n      <td>0.617008</td>\n    </tr>\n    <tr>\n      <th>Random Forest</th>\n      <td>0.688569</td>\n      <td>0.627573</td>\n      <td>0.762699</td>\n    </tr>\n    <tr>\n      <th>XGB Classifier</th>\n      <td>0.720244</td>\n      <td>0.662508</td>\n      <td>0.789004</td>\n    </tr>\n    <tr>\n      <th>Naive Bayes</th>\n      <td>0.436333</td>\n      <td>0.328135</td>\n      <td>0.650990</td>\n    </tr>\n    <tr>\n      <th>K-Nearest Neighbor</th>\n      <td>0.349398</td>\n      <td>0.253275</td>\n      <td>0.563107</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the result metrics for the test dta into a dataframe\n",
    "df_test_results = df_model_results(trained_models, X_test, y_test)\n",
    "df_test_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def bo_tune_xgb(max_depth, gamma, eta):\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'max_depth': int(max_depth),\n",
    "        'eta': eta,\n",
    "        'eval_metric': 'aucpr'\n",
    "    }\n",
    "\n",
    "    #Cross validating with the specified parameters in 5 folds and 70 iterations\n",
    "    cv_result = xgb.cv(params, training_xgb_matrix, num_boost_round=70, nfold=5)\n",
    "    #Return the resul\n",
    "    cv_result = cv_result['train-aucpr-mean'].iloc[-1]\n",
    "    return 1.0 * cv_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Instantiate a BayesianOptimization\n",
    "xgb_bo = BayesianOptimization(\n",
    "    bo_tune_xgb, {\n",
    "        'max_depth': (3, 7),\n",
    "        'gamma': (0, 1),\n",
    "        'eta': (0.01, 0.4),\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Group the train data into a xgb.DMatrix\n",
    "training_xgb_matrix = xgb.DMatrix(X_train, label=y_train)\n",
    "test_xgb_matrix = xgb.DMatrix(X_test, label=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    eta    |   gamma   | max_depth |\n",
      "-------------------------------------------------------------\n",
      "| \u001B[0m1        \u001B[0m | \u001B[0m0.8452   \u001B[0m | \u001B[0m0.1869   \u001B[0m | \u001B[0m0.9652   \u001B[0m | \u001B[0m4.432    \u001B[0m |\n",
      "| \u001B[95m2        \u001B[0m | \u001B[95m0.9106   \u001B[0m | \u001B[95m0.3786   \u001B[0m | \u001B[95m0.4149   \u001B[0m | \u001B[95m6.661    \u001B[0m |\n",
      "| \u001B[0m3        \u001B[0m | \u001B[0m0.831    \u001B[0m | \u001B[0m0.05232  \u001B[0m | \u001B[0m0.06874  \u001B[0m | \u001B[0m6.202    \u001B[0m |\n",
      "| \u001B[0m4        \u001B[0m | \u001B[0m0.8619   \u001B[0m | \u001B[0m0.119    \u001B[0m | \u001B[0m0.6762   \u001B[0m | \u001B[0m6.994    \u001B[0m |\n",
      "| \u001B[0m5        \u001B[0m | \u001B[0m0.7861   \u001B[0m | \u001B[0m0.02774  \u001B[0m | \u001B[0m0.4576   \u001B[0m | \u001B[0m4.14     \u001B[0m |\n",
      "| \u001B[0m6        \u001B[0m | \u001B[0m0.8441   \u001B[0m | \u001B[0m0.3629   \u001B[0m | \u001B[0m0.9114   \u001B[0m | \u001B[0m3.305    \u001B[0m |\n",
      "| \u001B[0m7        \u001B[0m | \u001B[0m0.8597   \u001B[0m | \u001B[0m0.1783   \u001B[0m | \u001B[0m0.5746   \u001B[0m | \u001B[0m5.99     \u001B[0m |\n",
      "| \u001B[0m8        \u001B[0m | \u001B[0m0.8281   \u001B[0m | \u001B[0m0.1991   \u001B[0m | \u001B[0m0.4917   \u001B[0m | \u001B[0m3.658    \u001B[0m |\n",
      "| \u001B[0m9        \u001B[0m | \u001B[0m0.8418   \u001B[0m | \u001B[0m0.3222   \u001B[0m | \u001B[0m0.8802   \u001B[0m | \u001B[0m3.477    \u001B[0m |\n",
      "| \u001B[0m10       \u001B[0m | \u001B[0m0.8304   \u001B[0m | \u001B[0m0.1158   \u001B[0m | \u001B[0m0.547    \u001B[0m | \u001B[0m4.62     \u001B[0m |\n",
      "| \u001B[95m11       \u001B[0m | \u001B[95m0.9174   \u001B[0m | \u001B[95m0.4      \u001B[0m | \u001B[95m0.6825   \u001B[0m | \u001B[95m6.531    \u001B[0m |\n",
      "| \u001B[0m12       \u001B[0m | \u001B[0m0.9174   \u001B[0m | \u001B[0m0.4      \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m6.33     \u001B[0m |\n",
      "| \u001B[0m13       \u001B[0m | \u001B[0m0.8925   \u001B[0m | \u001B[0m0.4      \u001B[0m | \u001B[0m1.0      \u001B[0m | \u001B[0m5.429    \u001B[0m |\n",
      "| \u001B[95m14       \u001B[0m | \u001B[95m0.9399   \u001B[0m | \u001B[95m0.4      \u001B[0m | \u001B[95m0.0      \u001B[0m | \u001B[95m7.0      \u001B[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the optimization\n",
    "xgb_bo.maximize(n_iter=6, init_points=8)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': 0.4, 'gamma': 0.0, 'max_depth': 7.0}\n"
     ]
    }
   ],
   "source": [
    "# Show the best hyperparameters\n",
    "params = xgb_bo.max['params']\n",
    "print(params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-aucpr:0.77340\ttrain-aucpr:0.77031\n",
      "[1]\teval-aucpr:0.79360\ttrain-aucpr:0.79579\n",
      "[2]\teval-aucpr:0.80517\ttrain-aucpr:0.81203\n",
      "[3]\teval-aucpr:0.80748\ttrain-aucpr:0.81581\n",
      "[4]\teval-aucpr:0.81247\ttrain-aucpr:0.82120\n",
      "[5]\teval-aucpr:0.81456\ttrain-aucpr:0.82496\n",
      "[6]\teval-aucpr:0.82135\ttrain-aucpr:0.83151\n",
      "[7]\teval-aucpr:0.82306\ttrain-aucpr:0.83587\n",
      "[8]\teval-aucpr:0.82393\ttrain-aucpr:0.83892\n",
      "[9]\teval-aucpr:0.82563\ttrain-aucpr:0.84064\n",
      "[10]\teval-aucpr:0.82604\ttrain-aucpr:0.84465\n",
      "[11]\teval-aucpr:0.82502\ttrain-aucpr:0.84764\n",
      "[12]\teval-aucpr:0.82588\ttrain-aucpr:0.85003\n",
      "[13]\teval-aucpr:0.82665\ttrain-aucpr:0.85238\n",
      "[14]\teval-aucpr:0.82806\ttrain-aucpr:0.85442\n",
      "[15]\teval-aucpr:0.82741\ttrain-aucpr:0.85921\n",
      "[16]\teval-aucpr:0.82959\ttrain-aucpr:0.86283\n",
      "[17]\teval-aucpr:0.82968\ttrain-aucpr:0.86436\n",
      "[18]\teval-aucpr:0.83044\ttrain-aucpr:0.86506\n",
      "[19]\teval-aucpr:0.83142\ttrain-aucpr:0.86697\n",
      "[20]\teval-aucpr:0.83093\ttrain-aucpr:0.86883\n",
      "[21]\teval-aucpr:0.83093\ttrain-aucpr:0.87010\n",
      "[22]\teval-aucpr:0.83102\ttrain-aucpr:0.87223\n",
      "[23]\teval-aucpr:0.83015\ttrain-aucpr:0.87400\n",
      "[24]\teval-aucpr:0.83017\ttrain-aucpr:0.87517\n",
      "[25]\teval-aucpr:0.83086\ttrain-aucpr:0.87592\n",
      "[26]\teval-aucpr:0.83128\ttrain-aucpr:0.87643\n",
      "[27]\teval-aucpr:0.83077\ttrain-aucpr:0.87786\n",
      "[28]\teval-aucpr:0.83119\ttrain-aucpr:0.88133\n",
      "[29]\teval-aucpr:0.83184\ttrain-aucpr:0.88179\n",
      "[30]\teval-aucpr:0.83194\ttrain-aucpr:0.88337\n",
      "[31]\teval-aucpr:0.83169\ttrain-aucpr:0.88433\n",
      "[32]\teval-aucpr:0.83228\ttrain-aucpr:0.88455\n",
      "[33]\teval-aucpr:0.83225\ttrain-aucpr:0.88495\n",
      "[34]\teval-aucpr:0.83253\ttrain-aucpr:0.88600\n",
      "[35]\teval-aucpr:0.83267\ttrain-aucpr:0.88658\n",
      "[36]\teval-aucpr:0.83269\ttrain-aucpr:0.88795\n",
      "[37]\teval-aucpr:0.83225\ttrain-aucpr:0.88895\n",
      "[38]\teval-aucpr:0.83184\ttrain-aucpr:0.89038\n",
      "[39]\teval-aucpr:0.83226\ttrain-aucpr:0.89097\n",
      "[40]\teval-aucpr:0.83216\ttrain-aucpr:0.89179\n",
      "[41]\teval-aucpr:0.83262\ttrain-aucpr:0.89174\n",
      "[42]\teval-aucpr:0.83271\ttrain-aucpr:0.89303\n",
      "[43]\teval-aucpr:0.83281\ttrain-aucpr:0.89605\n",
      "[44]\teval-aucpr:0.83151\ttrain-aucpr:0.89858\n",
      "[45]\teval-aucpr:0.83163\ttrain-aucpr:0.89988\n",
      "[46]\teval-aucpr:0.83136\ttrain-aucpr:0.90155\n",
      "[47]\teval-aucpr:0.83085\ttrain-aucpr:0.90318\n",
      "[48]\teval-aucpr:0.83054\ttrain-aucpr:0.90496\n",
      "[49]\teval-aucpr:0.83091\ttrain-aucpr:0.90531\n",
      "[50]\teval-aucpr:0.83105\ttrain-aucpr:0.90563\n",
      "[51]\teval-aucpr:0.83114\ttrain-aucpr:0.90585\n",
      "[52]\teval-aucpr:0.83125\ttrain-aucpr:0.90604\n",
      "[53]\teval-aucpr:0.83119\ttrain-aucpr:0.90755\n",
      "[54]\teval-aucpr:0.83133\ttrain-aucpr:0.90763\n",
      "[55]\teval-aucpr:0.83127\ttrain-aucpr:0.90811\n",
      "[56]\teval-aucpr:0.83134\ttrain-aucpr:0.90965\n",
      "[57]\teval-aucpr:0.83136\ttrain-aucpr:0.91036\n",
      "[58]\teval-aucpr:0.83148\ttrain-aucpr:0.91105\n",
      "[59]\teval-aucpr:0.83139\ttrain-aucpr:0.91188\n",
      "[60]\teval-aucpr:0.83135\ttrain-aucpr:0.91329\n",
      "[61]\teval-aucpr:0.83120\ttrain-aucpr:0.91376\n",
      "[62]\teval-aucpr:0.83108\ttrain-aucpr:0.91473\n",
      "[63]\teval-aucpr:0.83098\ttrain-aucpr:0.91590\n",
      "[64]\teval-aucpr:0.83114\ttrain-aucpr:0.91589\n",
      "[65]\teval-aucpr:0.83087\ttrain-aucpr:0.91753\n",
      "[66]\teval-aucpr:0.83087\ttrain-aucpr:0.91829\n",
      "[67]\teval-aucpr:0.83053\ttrain-aucpr:0.92047\n",
      "[68]\teval-aucpr:0.83007\ttrain-aucpr:0.92201\n",
      "[69]\teval-aucpr:0.82994\ttrain-aucpr:0.92341\n",
      "[70]\teval-aucpr:0.82953\ttrain-aucpr:0.92506\n",
      "[71]\teval-aucpr:0.82975\ttrain-aucpr:0.92507\n",
      "[72]\teval-aucpr:0.82910\ttrain-aucpr:0.92631\n",
      "[73]\teval-aucpr:0.82872\ttrain-aucpr:0.92747\n",
      "[74]\teval-aucpr:0.82873\ttrain-aucpr:0.92861\n",
      "[75]\teval-aucpr:0.82893\ttrain-aucpr:0.92982\n",
      "[76]\teval-aucpr:0.82894\ttrain-aucpr:0.93021\n",
      "[77]\teval-aucpr:0.82906\ttrain-aucpr:0.93030\n",
      "[78]\teval-aucpr:0.82971\ttrain-aucpr:0.93213\n",
      "[79]\teval-aucpr:0.82944\ttrain-aucpr:0.93306\n",
      "[80]\teval-aucpr:0.82977\ttrain-aucpr:0.93326\n",
      "[81]\teval-aucpr:0.82976\ttrain-aucpr:0.93362\n",
      "[82]\teval-aucpr:0.82942\ttrain-aucpr:0.93475\n",
      "[83]\teval-aucpr:0.82918\ttrain-aucpr:0.93565\n",
      "[84]\teval-aucpr:0.82924\ttrain-aucpr:0.93581\n",
      "[85]\teval-aucpr:0.82953\ttrain-aucpr:0.93608\n",
      "[86]\teval-aucpr:0.82969\ttrain-aucpr:0.93740\n",
      "[87]\teval-aucpr:0.82941\ttrain-aucpr:0.93882\n",
      "[88]\teval-aucpr:0.82933\ttrain-aucpr:0.94039\n",
      "[89]\teval-aucpr:0.82955\ttrain-aucpr:0.94061\n",
      "[90]\teval-aucpr:0.82978\ttrain-aucpr:0.94080\n",
      "[91]\teval-aucpr:0.82980\ttrain-aucpr:0.94110\n",
      "[92]\teval-aucpr:0.83000\ttrain-aucpr:0.94217\n",
      "[93]\teval-aucpr:0.82953\ttrain-aucpr:0.94262\n",
      "[94]\teval-aucpr:0.82966\ttrain-aucpr:0.94262\n",
      "[95]\teval-aucpr:0.82933\ttrain-aucpr:0.94313\n",
      "[96]\teval-aucpr:0.82917\ttrain-aucpr:0.94327\n",
      "[97]\teval-aucpr:0.82908\ttrain-aucpr:0.94390\n",
      "[98]\teval-aucpr:0.82856\ttrain-aucpr:0.94456\n",
      "[99]\teval-aucpr:0.82843\ttrain-aucpr:0.94471\n",
      "[100]\teval-aucpr:0.82791\ttrain-aucpr:0.94606\n",
      "[101]\teval-aucpr:0.82827\ttrain-aucpr:0.94679\n",
      "[102]\teval-aucpr:0.82834\ttrain-aucpr:0.94757\n",
      "[103]\teval-aucpr:0.82841\ttrain-aucpr:0.94816\n",
      "[104]\teval-aucpr:0.82859\ttrain-aucpr:0.94934\n",
      "[105]\teval-aucpr:0.82840\ttrain-aucpr:0.95032\n",
      "[106]\teval-aucpr:0.82835\ttrain-aucpr:0.95052\n",
      "[107]\teval-aucpr:0.82823\ttrain-aucpr:0.95120\n",
      "[108]\teval-aucpr:0.82836\ttrain-aucpr:0.95149\n",
      "[109]\teval-aucpr:0.82853\ttrain-aucpr:0.95155\n",
      "[110]\teval-aucpr:0.82853\ttrain-aucpr:0.95184\n",
      "[111]\teval-aucpr:0.82774\ttrain-aucpr:0.95341\n",
      "[112]\teval-aucpr:0.82737\ttrain-aucpr:0.95408\n",
      "[113]\teval-aucpr:0.82643\ttrain-aucpr:0.95474\n",
      "[114]\teval-aucpr:0.82651\ttrain-aucpr:0.95509\n",
      "[115]\teval-aucpr:0.82625\ttrain-aucpr:0.95572\n",
      "[116]\teval-aucpr:0.82611\ttrain-aucpr:0.95588\n",
      "[117]\teval-aucpr:0.82584\ttrain-aucpr:0.95641\n",
      "[118]\teval-aucpr:0.82567\ttrain-aucpr:0.95714\n",
      "[119]\teval-aucpr:0.82555\ttrain-aucpr:0.95741\n",
      "[120]\teval-aucpr:0.82552\ttrain-aucpr:0.95855\n",
      "[121]\teval-aucpr:0.82604\ttrain-aucpr:0.95924\n",
      "[122]\teval-aucpr:0.82605\ttrain-aucpr:0.96044\n",
      "[123]\teval-aucpr:0.82601\ttrain-aucpr:0.96092\n",
      "[124]\teval-aucpr:0.82598\ttrain-aucpr:0.96159\n",
      "[125]\teval-aucpr:0.82582\ttrain-aucpr:0.96175\n",
      "[126]\teval-aucpr:0.82571\ttrain-aucpr:0.96202\n",
      "[127]\teval-aucpr:0.82546\ttrain-aucpr:0.96265\n",
      "[128]\teval-aucpr:0.82524\ttrain-aucpr:0.96324\n",
      "[129]\teval-aucpr:0.82505\ttrain-aucpr:0.96428\n",
      "[130]\teval-aucpr:0.82458\ttrain-aucpr:0.96491\n",
      "[131]\teval-aucpr:0.82444\ttrain-aucpr:0.96541\n",
      "[132]\teval-aucpr:0.82438\ttrain-aucpr:0.96589\n",
      "[133]\teval-aucpr:0.82436\ttrain-aucpr:0.96596\n",
      "[134]\teval-aucpr:0.82460\ttrain-aucpr:0.96619\n",
      "[135]\teval-aucpr:0.82470\ttrain-aucpr:0.96727\n",
      "[136]\teval-aucpr:0.82483\ttrain-aucpr:0.96853\n",
      "[137]\teval-aucpr:0.82478\ttrain-aucpr:0.96879\n",
      "[138]\teval-aucpr:0.82480\ttrain-aucpr:0.96931\n",
      "[139]\teval-aucpr:0.82467\ttrain-aucpr:0.96939\n",
      "[140]\teval-aucpr:0.82423\ttrain-aucpr:0.96981\n",
      "[141]\teval-aucpr:0.82391\ttrain-aucpr:0.97045\n",
      "[142]\teval-aucpr:0.82358\ttrain-aucpr:0.97082\n",
      "[143]\teval-aucpr:0.82339\ttrain-aucpr:0.97103\n",
      "[144]\teval-aucpr:0.82316\ttrain-aucpr:0.97139\n",
      "[145]\teval-aucpr:0.82340\ttrain-aucpr:0.97191\n",
      "[146]\teval-aucpr:0.82330\ttrain-aucpr:0.97239\n",
      "[147]\teval-aucpr:0.82245\ttrain-aucpr:0.97310\n",
      "[148]\teval-aucpr:0.82236\ttrain-aucpr:0.97320\n",
      "[149]\teval-aucpr:0.82248\ttrain-aucpr:0.97334\n",
      "[150]\teval-aucpr:0.82228\ttrain-aucpr:0.97365\n",
      "[151]\teval-aucpr:0.82248\ttrain-aucpr:0.97403\n",
      "[152]\teval-aucpr:0.82258\ttrain-aucpr:0.97440\n",
      "[153]\teval-aucpr:0.82215\ttrain-aucpr:0.97484\n",
      "[154]\teval-aucpr:0.82214\ttrain-aucpr:0.97535\n",
      "[155]\teval-aucpr:0.82215\ttrain-aucpr:0.97530\n",
      "[156]\teval-aucpr:0.82204\ttrain-aucpr:0.97564\n",
      "[157]\teval-aucpr:0.82205\ttrain-aucpr:0.97587\n",
      "[158]\teval-aucpr:0.82194\ttrain-aucpr:0.97623\n",
      "[159]\teval-aucpr:0.82198\ttrain-aucpr:0.97640\n",
      "[160]\teval-aucpr:0.82201\ttrain-aucpr:0.97641\n",
      "[161]\teval-aucpr:0.82208\ttrain-aucpr:0.97689\n",
      "[162]\teval-aucpr:0.82199\ttrain-aucpr:0.97730\n",
      "[163]\teval-aucpr:0.82202\ttrain-aucpr:0.97734\n",
      "[164]\teval-aucpr:0.82218\ttrain-aucpr:0.97817\n",
      "[165]\teval-aucpr:0.82200\ttrain-aucpr:0.97860\n",
      "[166]\teval-aucpr:0.82200\ttrain-aucpr:0.97919\n",
      "[167]\teval-aucpr:0.82181\ttrain-aucpr:0.97965\n",
      "[168]\teval-aucpr:0.82194\ttrain-aucpr:0.97971\n",
      "[169]\teval-aucpr:0.82197\ttrain-aucpr:0.97993\n",
      "[170]\teval-aucpr:0.82159\ttrain-aucpr:0.98053\n",
      "[171]\teval-aucpr:0.82152\ttrain-aucpr:0.98133\n",
      "[172]\teval-aucpr:0.82163\ttrain-aucpr:0.98168\n",
      "[173]\teval-aucpr:0.82142\ttrain-aucpr:0.98228\n",
      "[174]\teval-aucpr:0.82133\ttrain-aucpr:0.98240\n",
      "[175]\teval-aucpr:0.82137\ttrain-aucpr:0.98245\n",
      "[176]\teval-aucpr:0.82134\ttrain-aucpr:0.98248\n",
      "[177]\teval-aucpr:0.82137\ttrain-aucpr:0.98244\n",
      "[178]\teval-aucpr:0.82139\ttrain-aucpr:0.98269\n",
      "[179]\teval-aucpr:0.82152\ttrain-aucpr:0.98287\n",
      "[180]\teval-aucpr:0.82175\ttrain-aucpr:0.98325\n",
      "[181]\teval-aucpr:0.82153\ttrain-aucpr:0.98375\n",
      "[182]\teval-aucpr:0.82127\ttrain-aucpr:0.98408\n",
      "[183]\teval-aucpr:0.82133\ttrain-aucpr:0.98410\n",
      "[184]\teval-aucpr:0.82133\ttrain-aucpr:0.98419\n",
      "[185]\teval-aucpr:0.82134\ttrain-aucpr:0.98437\n",
      "[186]\teval-aucpr:0.82128\ttrain-aucpr:0.98489\n",
      "[187]\teval-aucpr:0.82164\ttrain-aucpr:0.98526\n",
      "[188]\teval-aucpr:0.82157\ttrain-aucpr:0.98551\n",
      "[189]\teval-aucpr:0.82155\ttrain-aucpr:0.98564\n",
      "[190]\teval-aucpr:0.82126\ttrain-aucpr:0.98600\n",
      "[191]\teval-aucpr:0.82125\ttrain-aucpr:0.98611\n",
      "[192]\teval-aucpr:0.82103\ttrain-aucpr:0.98624\n",
      "[193]\teval-aucpr:0.82103\ttrain-aucpr:0.98631\n",
      "[194]\teval-aucpr:0.82093\ttrain-aucpr:0.98634\n",
      "[195]\teval-aucpr:0.82076\ttrain-aucpr:0.98642\n",
      "[196]\teval-aucpr:0.82059\ttrain-aucpr:0.98654\n",
      "[197]\teval-aucpr:0.82057\ttrain-aucpr:0.98660\n",
      "[198]\teval-aucpr:0.82063\ttrain-aucpr:0.98661\n",
      "[199]\teval-aucpr:0.82034\ttrain-aucpr:0.98677\n",
      "[200]\teval-aucpr:0.82024\ttrain-aucpr:0.98685\n",
      "[201]\teval-aucpr:0.82025\ttrain-aucpr:0.98698\n",
      "[202]\teval-aucpr:0.82000\ttrain-aucpr:0.98740\n",
      "[203]\teval-aucpr:0.82007\ttrain-aucpr:0.98743\n",
      "[204]\teval-aucpr:0.81943\ttrain-aucpr:0.98796\n",
      "[205]\teval-aucpr:0.81934\ttrain-aucpr:0.98838\n",
      "[206]\teval-aucpr:0.81935\ttrain-aucpr:0.98859\n",
      "[207]\teval-aucpr:0.81931\ttrain-aucpr:0.98887\n",
      "[208]\teval-aucpr:0.81926\ttrain-aucpr:0.98912\n",
      "[209]\teval-aucpr:0.81915\ttrain-aucpr:0.98934\n",
      "[210]\teval-aucpr:0.81915\ttrain-aucpr:0.98938\n",
      "[211]\teval-aucpr:0.81893\ttrain-aucpr:0.98956\n",
      "[212]\teval-aucpr:0.81911\ttrain-aucpr:0.98962\n",
      "[213]\teval-aucpr:0.81913\ttrain-aucpr:0.98980\n",
      "[214]\teval-aucpr:0.81909\ttrain-aucpr:0.99004\n",
      "[215]\teval-aucpr:0.81932\ttrain-aucpr:0.99029\n",
      "[216]\teval-aucpr:0.81941\ttrain-aucpr:0.99042\n",
      "[217]\teval-aucpr:0.81949\ttrain-aucpr:0.99083\n",
      "[218]\teval-aucpr:0.81943\ttrain-aucpr:0.99111\n",
      "[219]\teval-aucpr:0.81940\ttrain-aucpr:0.99133\n",
      "[220]\teval-aucpr:0.81933\ttrain-aucpr:0.99136\n",
      "[221]\teval-aucpr:0.81940\ttrain-aucpr:0.99168\n",
      "[222]\teval-aucpr:0.81927\ttrain-aucpr:0.99179\n",
      "[223]\teval-aucpr:0.81937\ttrain-aucpr:0.99204\n",
      "[224]\teval-aucpr:0.81945\ttrain-aucpr:0.99214\n",
      "[225]\teval-aucpr:0.81949\ttrain-aucpr:0.99212\n",
      "[226]\teval-aucpr:0.81937\ttrain-aucpr:0.99222\n",
      "[227]\teval-aucpr:0.81928\ttrain-aucpr:0.99228\n",
      "[228]\teval-aucpr:0.81938\ttrain-aucpr:0.99247\n",
      "[229]\teval-aucpr:0.81941\ttrain-aucpr:0.99263\n",
      "[230]\teval-aucpr:0.81960\ttrain-aucpr:0.99271\n",
      "[231]\teval-aucpr:0.81946\ttrain-aucpr:0.99282\n",
      "[232]\teval-aucpr:0.81948\ttrain-aucpr:0.99306\n",
      "[233]\teval-aucpr:0.81957\ttrain-aucpr:0.99322\n",
      "[234]\teval-aucpr:0.81950\ttrain-aucpr:0.99331\n",
      "[235]\teval-aucpr:0.81933\ttrain-aucpr:0.99345\n",
      "[236]\teval-aucpr:0.81939\ttrain-aucpr:0.99349\n",
      "[237]\teval-aucpr:0.81914\ttrain-aucpr:0.99358\n",
      "[238]\teval-aucpr:0.81918\ttrain-aucpr:0.99358\n",
      "[239]\teval-aucpr:0.81933\ttrain-aucpr:0.99359\n",
      "[240]\teval-aucpr:0.81930\ttrain-aucpr:0.99362\n",
      "[241]\teval-aucpr:0.81930\ttrain-aucpr:0.99388\n",
      "[242]\teval-aucpr:0.81926\ttrain-aucpr:0.99393\n",
      "[243]\teval-aucpr:0.81914\ttrain-aucpr:0.99399\n",
      "[244]\teval-aucpr:0.81938\ttrain-aucpr:0.99410\n",
      "[245]\teval-aucpr:0.81947\ttrain-aucpr:0.99410\n",
      "[246]\teval-aucpr:0.81948\ttrain-aucpr:0.99414\n",
      "[247]\teval-aucpr:0.81950\ttrain-aucpr:0.99419\n",
      "[248]\teval-aucpr:0.81944\ttrain-aucpr:0.99420\n",
      "[249]\teval-aucpr:0.81917\ttrain-aucpr:0.99432\n",
      "[250]\teval-aucpr:0.81909\ttrain-aucpr:0.99437\n",
      "[251]\teval-aucpr:0.81906\ttrain-aucpr:0.99438\n",
      "[252]\teval-aucpr:0.81923\ttrain-aucpr:0.99439\n",
      "[253]\teval-aucpr:0.81916\ttrain-aucpr:0.99440\n",
      "[254]\teval-aucpr:0.81902\ttrain-aucpr:0.99468\n",
      "[255]\teval-aucpr:0.81827\ttrain-aucpr:0.99501\n",
      "[256]\teval-aucpr:0.81834\ttrain-aucpr:0.99522\n",
      "[257]\teval-aucpr:0.81822\ttrain-aucpr:0.99534\n",
      "[258]\teval-aucpr:0.81812\ttrain-aucpr:0.99538\n",
      "[259]\teval-aucpr:0.81827\ttrain-aucpr:0.99553\n",
      "[260]\teval-aucpr:0.81809\ttrain-aucpr:0.99567\n",
      "[261]\teval-aucpr:0.81807\ttrain-aucpr:0.99581\n",
      "[262]\teval-aucpr:0.81804\ttrain-aucpr:0.99592\n",
      "[263]\teval-aucpr:0.81811\ttrain-aucpr:0.99594\n",
      "[264]\teval-aucpr:0.81803\ttrain-aucpr:0.99594\n",
      "[265]\teval-aucpr:0.81794\ttrain-aucpr:0.99598\n",
      "[266]\teval-aucpr:0.81796\ttrain-aucpr:0.99600\n",
      "[267]\teval-aucpr:0.81794\ttrain-aucpr:0.99600\n",
      "[268]\teval-aucpr:0.81800\ttrain-aucpr:0.99602\n",
      "[269]\teval-aucpr:0.81816\ttrain-aucpr:0.99601\n",
      "[270]\teval-aucpr:0.81790\ttrain-aucpr:0.99615\n",
      "[271]\teval-aucpr:0.81765\ttrain-aucpr:0.99631\n",
      "[272]\teval-aucpr:0.81803\ttrain-aucpr:0.99646\n",
      "[273]\teval-aucpr:0.81820\ttrain-aucpr:0.99657\n",
      "[274]\teval-aucpr:0.81776\ttrain-aucpr:0.99671\n",
      "[275]\teval-aucpr:0.81763\ttrain-aucpr:0.99680\n",
      "[276]\teval-aucpr:0.81751\ttrain-aucpr:0.99690\n",
      "[277]\teval-aucpr:0.81759\ttrain-aucpr:0.99691\n",
      "[278]\teval-aucpr:0.81761\ttrain-aucpr:0.99693\n",
      "[279]\teval-aucpr:0.81758\ttrain-aucpr:0.99706\n",
      "[280]\teval-aucpr:0.81745\ttrain-aucpr:0.99709\n",
      "[281]\teval-aucpr:0.81719\ttrain-aucpr:0.99711\n",
      "[282]\teval-aucpr:0.81719\ttrain-aucpr:0.99721\n",
      "[283]\teval-aucpr:0.81726\ttrain-aucpr:0.99722\n",
      "[284]\teval-aucpr:0.81699\ttrain-aucpr:0.99732\n",
      "[285]\teval-aucpr:0.81712\ttrain-aucpr:0.99738\n",
      "[286]\teval-aucpr:0.81716\ttrain-aucpr:0.99738\n",
      "[287]\teval-aucpr:0.81723\ttrain-aucpr:0.99741\n",
      "[288]\teval-aucpr:0.81718\ttrain-aucpr:0.99745\n",
      "[289]\teval-aucpr:0.81715\ttrain-aucpr:0.99748\n",
      "[290]\teval-aucpr:0.81715\ttrain-aucpr:0.99752\n",
      "[291]\teval-aucpr:0.81709\ttrain-aucpr:0.99754\n",
      "[292]\teval-aucpr:0.81701\ttrain-aucpr:0.99760\n",
      "[293]\teval-aucpr:0.81686\ttrain-aucpr:0.99766\n",
      "[294]\teval-aucpr:0.81687\ttrain-aucpr:0.99776\n",
      "[295]\teval-aucpr:0.81694\ttrain-aucpr:0.99776\n",
      "[296]\teval-aucpr:0.81688\ttrain-aucpr:0.99786\n",
      "[297]\teval-aucpr:0.81672\ttrain-aucpr:0.99787\n",
      "[298]\teval-aucpr:0.81675\ttrain-aucpr:0.99786\n",
      "[299]\teval-aucpr:0.81669\ttrain-aucpr:0.99793\n",
      "[300]\teval-aucpr:0.81680\ttrain-aucpr:0.99801\n",
      "[301]\teval-aucpr:0.81677\ttrain-aucpr:0.99805\n",
      "[302]\teval-aucpr:0.81674\ttrain-aucpr:0.99806\n",
      "[303]\teval-aucpr:0.81683\ttrain-aucpr:0.99807\n",
      "[304]\teval-aucpr:0.81668\ttrain-aucpr:0.99808\n",
      "[305]\teval-aucpr:0.81661\ttrain-aucpr:0.99809\n",
      "[306]\teval-aucpr:0.81657\ttrain-aucpr:0.99809\n",
      "[307]\teval-aucpr:0.81683\ttrain-aucpr:0.99820\n",
      "[308]\teval-aucpr:0.81680\ttrain-aucpr:0.99821\n",
      "[309]\teval-aucpr:0.81684\ttrain-aucpr:0.99822\n",
      "[310]\teval-aucpr:0.81686\ttrain-aucpr:0.99827\n",
      "[311]\teval-aucpr:0.81671\ttrain-aucpr:0.99829\n",
      "[312]\teval-aucpr:0.81660\ttrain-aucpr:0.99830\n",
      "[313]\teval-aucpr:0.81651\ttrain-aucpr:0.99831\n",
      "[314]\teval-aucpr:0.81657\ttrain-aucpr:0.99839\n",
      "[315]\teval-aucpr:0.81646\ttrain-aucpr:0.99841\n",
      "[316]\teval-aucpr:0.81624\ttrain-aucpr:0.99843\n",
      "[317]\teval-aucpr:0.81633\ttrain-aucpr:0.99852\n",
      "[318]\teval-aucpr:0.81620\ttrain-aucpr:0.99856\n",
      "[319]\teval-aucpr:0.81626\ttrain-aucpr:0.99856\n",
      "[320]\teval-aucpr:0.81608\ttrain-aucpr:0.99862\n",
      "[321]\teval-aucpr:0.81591\ttrain-aucpr:0.99866\n",
      "[322]\teval-aucpr:0.81579\ttrain-aucpr:0.99869\n",
      "[323]\teval-aucpr:0.81573\ttrain-aucpr:0.99870\n",
      "[324]\teval-aucpr:0.81591\ttrain-aucpr:0.99873\n",
      "[325]\teval-aucpr:0.81581\ttrain-aucpr:0.99874\n",
      "[326]\teval-aucpr:0.81573\ttrain-aucpr:0.99877\n",
      "[327]\teval-aucpr:0.81564\ttrain-aucpr:0.99879\n",
      "[328]\teval-aucpr:0.81549\ttrain-aucpr:0.99888\n",
      "[329]\teval-aucpr:0.81530\ttrain-aucpr:0.99891\n",
      "[330]\teval-aucpr:0.81530\ttrain-aucpr:0.99893\n",
      "[331]\teval-aucpr:0.81526\ttrain-aucpr:0.99893\n",
      "[332]\teval-aucpr:0.81528\ttrain-aucpr:0.99893\n",
      "[333]\teval-aucpr:0.81506\ttrain-aucpr:0.99897\n",
      "[334]\teval-aucpr:0.81508\ttrain-aucpr:0.99897\n",
      "[335]\teval-aucpr:0.81496\ttrain-aucpr:0.99899\n",
      "[336]\teval-aucpr:0.81496\ttrain-aucpr:0.99900\n",
      "[337]\teval-aucpr:0.81484\ttrain-aucpr:0.99900\n",
      "[338]\teval-aucpr:0.81492\ttrain-aucpr:0.99907\n",
      "[339]\teval-aucpr:0.81484\ttrain-aucpr:0.99913\n",
      "[340]\teval-aucpr:0.81480\ttrain-aucpr:0.99922\n",
      "[341]\teval-aucpr:0.81456\ttrain-aucpr:0.99924\n",
      "[342]\teval-aucpr:0.81456\ttrain-aucpr:0.99924\n",
      "[343]\teval-aucpr:0.81451\ttrain-aucpr:0.99925\n",
      "[344]\teval-aucpr:0.81440\ttrain-aucpr:0.99926\n",
      "[345]\teval-aucpr:0.81441\ttrain-aucpr:0.99927\n",
      "[346]\teval-aucpr:0.81435\ttrain-aucpr:0.99927\n",
      "[347]\teval-aucpr:0.81435\ttrain-aucpr:0.99928\n",
      "[348]\teval-aucpr:0.81440\ttrain-aucpr:0.99930\n",
      "[349]\teval-aucpr:0.81453\ttrain-aucpr:0.99930\n",
      "[350]\teval-aucpr:0.81452\ttrain-aucpr:0.99930\n",
      "[351]\teval-aucpr:0.81448\ttrain-aucpr:0.99930\n",
      "[352]\teval-aucpr:0.81439\ttrain-aucpr:0.99930\n",
      "[353]\teval-aucpr:0.81445\ttrain-aucpr:0.99933\n",
      "[354]\teval-aucpr:0.81432\ttrain-aucpr:0.99935\n",
      "[355]\teval-aucpr:0.81430\ttrain-aucpr:0.99935\n",
      "[356]\teval-aucpr:0.81429\ttrain-aucpr:0.99937\n",
      "[357]\teval-aucpr:0.81418\ttrain-aucpr:0.99937\n",
      "[358]\teval-aucpr:0.81419\ttrain-aucpr:0.99937\n",
      "[359]\teval-aucpr:0.81395\ttrain-aucpr:0.99939\n",
      "[360]\teval-aucpr:0.81374\ttrain-aucpr:0.99940\n",
      "[361]\teval-aucpr:0.81351\ttrain-aucpr:0.99941\n",
      "[362]\teval-aucpr:0.81344\ttrain-aucpr:0.99943\n",
      "[363]\teval-aucpr:0.81314\ttrain-aucpr:0.99946\n",
      "[364]\teval-aucpr:0.81297\ttrain-aucpr:0.99948\n",
      "[365]\teval-aucpr:0.81278\ttrain-aucpr:0.99950\n",
      "[366]\teval-aucpr:0.81285\ttrain-aucpr:0.99952\n",
      "[367]\teval-aucpr:0.81294\ttrain-aucpr:0.99953\n",
      "[368]\teval-aucpr:0.81307\ttrain-aucpr:0.99953\n",
      "[369]\teval-aucpr:0.81298\ttrain-aucpr:0.99955\n",
      "[370]\teval-aucpr:0.81300\ttrain-aucpr:0.99955\n",
      "[371]\teval-aucpr:0.81284\ttrain-aucpr:0.99955\n",
      "[372]\teval-aucpr:0.81282\ttrain-aucpr:0.99955\n",
      "[373]\teval-aucpr:0.81283\ttrain-aucpr:0.99955\n",
      "[374]\teval-aucpr:0.81283\ttrain-aucpr:0.99955\n",
      "[375]\teval-aucpr:0.81275\ttrain-aucpr:0.99955\n",
      "[376]\teval-aucpr:0.81272\ttrain-aucpr:0.99955\n",
      "[377]\teval-aucpr:0.81288\ttrain-aucpr:0.99957\n",
      "[378]\teval-aucpr:0.81292\ttrain-aucpr:0.99957\n",
      "[379]\teval-aucpr:0.81291\ttrain-aucpr:0.99957\n",
      "[380]\teval-aucpr:0.81280\ttrain-aucpr:0.99961\n",
      "[381]\teval-aucpr:0.81275\ttrain-aucpr:0.99962\n",
      "[382]\teval-aucpr:0.81284\ttrain-aucpr:0.99962\n",
      "[383]\teval-aucpr:0.81270\ttrain-aucpr:0.99963\n",
      "[384]\teval-aucpr:0.81270\ttrain-aucpr:0.99963\n",
      "[385]\teval-aucpr:0.81273\ttrain-aucpr:0.99963\n",
      "[386]\teval-aucpr:0.81273\ttrain-aucpr:0.99964\n",
      "[387]\teval-aucpr:0.81272\ttrain-aucpr:0.99964\n",
      "[388]\teval-aucpr:0.81251\ttrain-aucpr:0.99965\n",
      "[389]\teval-aucpr:0.81252\ttrain-aucpr:0.99967\n",
      "[390]\teval-aucpr:0.81243\ttrain-aucpr:0.99968\n",
      "[391]\teval-aucpr:0.81251\ttrain-aucpr:0.99967\n",
      "[392]\teval-aucpr:0.81256\ttrain-aucpr:0.99967\n",
      "[393]\teval-aucpr:0.81246\ttrain-aucpr:0.99968\n",
      "[394]\teval-aucpr:0.81251\ttrain-aucpr:0.99968\n",
      "[395]\teval-aucpr:0.81241\ttrain-aucpr:0.99969\n",
      "[396]\teval-aucpr:0.81250\ttrain-aucpr:0.99969\n",
      "[397]\teval-aucpr:0.81244\ttrain-aucpr:0.99969\n",
      "[398]\teval-aucpr:0.81243\ttrain-aucpr:0.99969\n",
      "[399]\teval-aucpr:0.81246\ttrain-aucpr:0.99969\n",
      "[400]\teval-aucpr:0.81240\ttrain-aucpr:0.99970\n",
      "[401]\teval-aucpr:0.81238\ttrain-aucpr:0.99972\n",
      "[402]\teval-aucpr:0.81234\ttrain-aucpr:0.99973\n",
      "[403]\teval-aucpr:0.81229\ttrain-aucpr:0.99973\n",
      "[404]\teval-aucpr:0.81220\ttrain-aucpr:0.99973\n",
      "[405]\teval-aucpr:0.81219\ttrain-aucpr:0.99974\n",
      "[406]\teval-aucpr:0.81174\ttrain-aucpr:0.99975\n",
      "[407]\teval-aucpr:0.81165\ttrain-aucpr:0.99975\n",
      "[408]\teval-aucpr:0.81175\ttrain-aucpr:0.99975\n",
      "[409]\teval-aucpr:0.81183\ttrain-aucpr:0.99975\n",
      "[410]\teval-aucpr:0.81181\ttrain-aucpr:0.99978\n",
      "[411]\teval-aucpr:0.81184\ttrain-aucpr:0.99977\n",
      "[412]\teval-aucpr:0.81178\ttrain-aucpr:0.99978\n",
      "[413]\teval-aucpr:0.81167\ttrain-aucpr:0.99978\n",
      "[414]\teval-aucpr:0.81178\ttrain-aucpr:0.99978\n",
      "[415]\teval-aucpr:0.81175\ttrain-aucpr:0.99978\n",
      "[416]\teval-aucpr:0.81188\ttrain-aucpr:0.99979\n",
      "[417]\teval-aucpr:0.81185\ttrain-aucpr:0.99979\n",
      "[418]\teval-aucpr:0.81179\ttrain-aucpr:0.99980\n",
      "[419]\teval-aucpr:0.81180\ttrain-aucpr:0.99980\n",
      "[420]\teval-aucpr:0.81171\ttrain-aucpr:0.99980\n",
      "[421]\teval-aucpr:0.81150\ttrain-aucpr:0.99980\n",
      "[422]\teval-aucpr:0.81139\ttrain-aucpr:0.99982\n",
      "[423]\teval-aucpr:0.81132\ttrain-aucpr:0.99983\n",
      "[424]\teval-aucpr:0.81108\ttrain-aucpr:0.99983\n",
      "[425]\teval-aucpr:0.81089\ttrain-aucpr:0.99983\n",
      "[426]\teval-aucpr:0.81080\ttrain-aucpr:0.99984\n",
      "[427]\teval-aucpr:0.81076\ttrain-aucpr:0.99984\n",
      "[428]\teval-aucpr:0.81076\ttrain-aucpr:0.99985\n",
      "[429]\teval-aucpr:0.81064\ttrain-aucpr:0.99985\n",
      "[430]\teval-aucpr:0.81057\ttrain-aucpr:0.99986\n",
      "[431]\teval-aucpr:0.81063\ttrain-aucpr:0.99986\n",
      "[432]\teval-aucpr:0.81023\ttrain-aucpr:0.99986\n",
      "[433]\teval-aucpr:0.81013\ttrain-aucpr:0.99988\n",
      "[434]\teval-aucpr:0.81023\ttrain-aucpr:0.99988\n",
      "[435]\teval-aucpr:0.81007\ttrain-aucpr:0.99989\n",
      "[436]\teval-aucpr:0.80998\ttrain-aucpr:0.99989\n",
      "[437]\teval-aucpr:0.81013\ttrain-aucpr:0.99989\n",
      "[438]\teval-aucpr:0.81043\ttrain-aucpr:0.99989\n",
      "[439]\teval-aucpr:0.81044\ttrain-aucpr:0.99989\n",
      "[440]\teval-aucpr:0.81033\ttrain-aucpr:0.99989\n",
      "[441]\teval-aucpr:0.81021\ttrain-aucpr:0.99989\n",
      "[442]\teval-aucpr:0.81020\ttrain-aucpr:0.99989\n",
      "[443]\teval-aucpr:0.81021\ttrain-aucpr:0.99989\n",
      "[444]\teval-aucpr:0.81036\ttrain-aucpr:0.99989\n",
      "[445]\teval-aucpr:0.81014\ttrain-aucpr:0.99990\n",
      "[446]\teval-aucpr:0.81012\ttrain-aucpr:0.99991\n",
      "[447]\teval-aucpr:0.81004\ttrain-aucpr:0.99991\n",
      "[448]\teval-aucpr:0.81012\ttrain-aucpr:0.99991\n",
      "[449]\teval-aucpr:0.80989\ttrain-aucpr:0.99991\n",
      "[450]\teval-aucpr:0.80988\ttrain-aucpr:0.99991\n",
      "[451]\teval-aucpr:0.80991\ttrain-aucpr:0.99991\n",
      "[452]\teval-aucpr:0.80995\ttrain-aucpr:0.99991\n",
      "[453]\teval-aucpr:0.80988\ttrain-aucpr:0.99992\n",
      "[454]\teval-aucpr:0.80991\ttrain-aucpr:0.99992\n",
      "[455]\teval-aucpr:0.80973\ttrain-aucpr:0.99992\n",
      "[456]\teval-aucpr:0.80955\ttrain-aucpr:0.99992\n",
      "[457]\teval-aucpr:0.80964\ttrain-aucpr:0.99992\n",
      "[458]\teval-aucpr:0.80948\ttrain-aucpr:0.99992\n",
      "[459]\teval-aucpr:0.80935\ttrain-aucpr:0.99992\n",
      "[460]\teval-aucpr:0.80917\ttrain-aucpr:0.99992\n",
      "[461]\teval-aucpr:0.80910\ttrain-aucpr:0.99992\n",
      "[462]\teval-aucpr:0.80893\ttrain-aucpr:0.99992\n",
      "[463]\teval-aucpr:0.80879\ttrain-aucpr:0.99992\n",
      "[464]\teval-aucpr:0.80875\ttrain-aucpr:0.99992\n",
      "[465]\teval-aucpr:0.80872\ttrain-aucpr:0.99992\n",
      "[466]\teval-aucpr:0.80881\ttrain-aucpr:0.99992\n",
      "[467]\teval-aucpr:0.80884\ttrain-aucpr:0.99992\n",
      "[468]\teval-aucpr:0.80873\ttrain-aucpr:0.99992\n",
      "[469]\teval-aucpr:0.80887\ttrain-aucpr:0.99992\n",
      "[470]\teval-aucpr:0.80892\ttrain-aucpr:0.99992\n",
      "[471]\teval-aucpr:0.80880\ttrain-aucpr:0.99993\n",
      "[472]\teval-aucpr:0.80863\ttrain-aucpr:0.99994\n",
      "[473]\teval-aucpr:0.80857\ttrain-aucpr:0.99994\n",
      "[474]\teval-aucpr:0.80852\ttrain-aucpr:0.99994\n",
      "[475]\teval-aucpr:0.80855\ttrain-aucpr:0.99994\n",
      "[476]\teval-aucpr:0.80874\ttrain-aucpr:0.99994\n",
      "[477]\teval-aucpr:0.80873\ttrain-aucpr:0.99995\n",
      "[478]\teval-aucpr:0.80879\ttrain-aucpr:0.99995\n",
      "[479]\teval-aucpr:0.80884\ttrain-aucpr:0.99995\n",
      "[480]\teval-aucpr:0.80884\ttrain-aucpr:0.99995\n",
      "[481]\teval-aucpr:0.80876\ttrain-aucpr:0.99995\n",
      "[482]\teval-aucpr:0.80874\ttrain-aucpr:0.99995\n",
      "[483]\teval-aucpr:0.80885\ttrain-aucpr:0.99995\n",
      "[484]\teval-aucpr:0.80878\ttrain-aucpr:0.99995\n",
      "[485]\teval-aucpr:0.80894\ttrain-aucpr:0.99995\n",
      "[486]\teval-aucpr:0.80894\ttrain-aucpr:0.99995\n",
      "[487]\teval-aucpr:0.80891\ttrain-aucpr:0.99995\n",
      "[488]\teval-aucpr:0.80902\ttrain-aucpr:0.99995\n",
      "[489]\teval-aucpr:0.80900\ttrain-aucpr:0.99995\n",
      "[490]\teval-aucpr:0.80897\ttrain-aucpr:0.99995\n",
      "[491]\teval-aucpr:0.80888\ttrain-aucpr:0.99995\n",
      "[492]\teval-aucpr:0.80876\ttrain-aucpr:0.99996\n",
      "[493]\teval-aucpr:0.80881\ttrain-aucpr:0.99996\n",
      "[494]\teval-aucpr:0.80890\ttrain-aucpr:0.99996\n",
      "[495]\teval-aucpr:0.80898\ttrain-aucpr:0.99996\n",
      "[496]\teval-aucpr:0.80892\ttrain-aucpr:0.99996\n",
      "[497]\teval-aucpr:0.80887\ttrain-aucpr:0.99996\n",
      "[498]\teval-aucpr:0.80871\ttrain-aucpr:0.99996\n",
      "[499]\teval-aucpr:0.80862\ttrain-aucpr:0.99996\n",
      "[500]\teval-aucpr:0.80863\ttrain-aucpr:0.99996\n",
      "[501]\teval-aucpr:0.80840\ttrain-aucpr:0.99997\n",
      "[502]\teval-aucpr:0.80851\ttrain-aucpr:0.99997\n",
      "[503]\teval-aucpr:0.80830\ttrain-aucpr:0.99998\n",
      "[504]\teval-aucpr:0.80797\ttrain-aucpr:0.99998\n",
      "[505]\teval-aucpr:0.80785\ttrain-aucpr:0.99998\n",
      "[506]\teval-aucpr:0.80786\ttrain-aucpr:0.99998\n",
      "[507]\teval-aucpr:0.80781\ttrain-aucpr:0.99998\n",
      "[508]\teval-aucpr:0.80794\ttrain-aucpr:0.99999\n",
      "[509]\teval-aucpr:0.80803\ttrain-aucpr:0.99999\n",
      "[510]\teval-aucpr:0.80802\ttrain-aucpr:0.99999\n",
      "[511]\teval-aucpr:0.80802\ttrain-aucpr:0.99999\n",
      "[512]\teval-aucpr:0.80801\ttrain-aucpr:0.99999\n",
      "[513]\teval-aucpr:0.80801\ttrain-aucpr:0.99999\n",
      "[514]\teval-aucpr:0.80813\ttrain-aucpr:0.99998\n",
      "[515]\teval-aucpr:0.80808\ttrain-aucpr:0.99998\n",
      "[516]\teval-aucpr:0.80809\ttrain-aucpr:0.99999\n",
      "[517]\teval-aucpr:0.80815\ttrain-aucpr:0.99999\n",
      "[518]\teval-aucpr:0.80808\ttrain-aucpr:0.99998\n",
      "[519]\teval-aucpr:0.80816\ttrain-aucpr:0.99998\n",
      "[520]\teval-aucpr:0.80812\ttrain-aucpr:0.99998\n",
      "[521]\teval-aucpr:0.80811\ttrain-aucpr:0.99998\n",
      "[522]\teval-aucpr:0.80804\ttrain-aucpr:0.99999\n",
      "[523]\teval-aucpr:0.80803\ttrain-aucpr:0.99999\n",
      "[524]\teval-aucpr:0.80801\ttrain-aucpr:0.99999\n",
      "[525]\teval-aucpr:0.80801\ttrain-aucpr:0.99999\n",
      "[526]\teval-aucpr:0.80785\ttrain-aucpr:0.99999\n",
      "[527]\teval-aucpr:0.80794\ttrain-aucpr:0.99999\n",
      "[528]\teval-aucpr:0.80798\ttrain-aucpr:0.99999\n",
      "[529]\teval-aucpr:0.80799\ttrain-aucpr:0.99999\n",
      "[530]\teval-aucpr:0.80797\ttrain-aucpr:0.99999\n",
      "[531]\teval-aucpr:0.80794\ttrain-aucpr:0.99999\n",
      "[532]\teval-aucpr:0.80775\ttrain-aucpr:0.99999\n",
      "[533]\teval-aucpr:0.80783\ttrain-aucpr:0.99999\n",
      "[534]\teval-aucpr:0.80790\ttrain-aucpr:0.99999\n",
      "[535]\teval-aucpr:0.80794\ttrain-aucpr:0.99999\n",
      "[536]\teval-aucpr:0.80775\ttrain-aucpr:0.99999\n",
      "[537]\teval-aucpr:0.80767\ttrain-aucpr:0.99999\n",
      "[538]\teval-aucpr:0.80761\ttrain-aucpr:0.99999\n",
      "[539]\teval-aucpr:0.80763\ttrain-aucpr:0.99999\n",
      "[540]\teval-aucpr:0.80755\ttrain-aucpr:0.99999\n",
      "[541]\teval-aucpr:0.80749\ttrain-aucpr:0.99999\n",
      "[542]\teval-aucpr:0.80738\ttrain-aucpr:0.99999\n",
      "[543]\teval-aucpr:0.80719\ttrain-aucpr:0.99999\n",
      "[544]\teval-aucpr:0.80705\ttrain-aucpr:0.99999\n",
      "[545]\teval-aucpr:0.80679\ttrain-aucpr:0.99999\n",
      "[546]\teval-aucpr:0.80671\ttrain-aucpr:0.99999\n",
      "[547]\teval-aucpr:0.80672\ttrain-aucpr:0.99999\n",
      "[548]\teval-aucpr:0.80690\ttrain-aucpr:0.99999\n",
      "[549]\teval-aucpr:0.80686\ttrain-aucpr:0.99999\n",
      "[550]\teval-aucpr:0.80687\ttrain-aucpr:0.99999\n",
      "[551]\teval-aucpr:0.80693\ttrain-aucpr:0.99999\n",
      "[552]\teval-aucpr:0.80685\ttrain-aucpr:0.99999\n",
      "[553]\teval-aucpr:0.80684\ttrain-aucpr:0.99999\n",
      "[554]\teval-aucpr:0.80684\ttrain-aucpr:0.99999\n",
      "[555]\teval-aucpr:0.80691\ttrain-aucpr:0.99999\n",
      "[556]\teval-aucpr:0.80695\ttrain-aucpr:0.99999\n",
      "[557]\teval-aucpr:0.80688\ttrain-aucpr:0.99999\n",
      "[558]\teval-aucpr:0.80685\ttrain-aucpr:0.99999\n",
      "[559]\teval-aucpr:0.80689\ttrain-aucpr:0.99999\n",
      "[560]\teval-aucpr:0.80682\ttrain-aucpr:0.99999\n",
      "[561]\teval-aucpr:0.80691\ttrain-aucpr:0.99999\n",
      "[562]\teval-aucpr:0.80651\ttrain-aucpr:1.00000\n",
      "[563]\teval-aucpr:0.80663\ttrain-aucpr:1.00000\n",
      "[564]\teval-aucpr:0.80650\ttrain-aucpr:1.00000\n",
      "[565]\teval-aucpr:0.80630\ttrain-aucpr:1.00000\n",
      "[566]\teval-aucpr:0.80636\ttrain-aucpr:1.00000\n",
      "[567]\teval-aucpr:0.80640\ttrain-aucpr:1.00000\n",
      "[568]\teval-aucpr:0.80658\ttrain-aucpr:1.00000\n",
      "[569]\teval-aucpr:0.80651\ttrain-aucpr:1.00000\n",
      "[570]\teval-aucpr:0.80655\ttrain-aucpr:1.00000\n",
      "[571]\teval-aucpr:0.80641\ttrain-aucpr:1.00000\n",
      "[572]\teval-aucpr:0.80631\ttrain-aucpr:1.00000\n",
      "[573]\teval-aucpr:0.80638\ttrain-aucpr:1.00000\n",
      "[574]\teval-aucpr:0.80633\ttrain-aucpr:1.00000\n",
      "[575]\teval-aucpr:0.80641\ttrain-aucpr:1.00000\n",
      "[576]\teval-aucpr:0.80639\ttrain-aucpr:1.00000\n",
      "[577]\teval-aucpr:0.80637\ttrain-aucpr:1.00000\n",
      "[578]\teval-aucpr:0.80639\ttrain-aucpr:1.00000\n",
      "[579]\teval-aucpr:0.80633\ttrain-aucpr:1.00000\n",
      "[580]\teval-aucpr:0.80624\ttrain-aucpr:1.00000\n",
      "[581]\teval-aucpr:0.80632\ttrain-aucpr:1.00000\n",
      "[582]\teval-aucpr:0.80628\ttrain-aucpr:1.00000\n",
      "[583]\teval-aucpr:0.80619\ttrain-aucpr:1.00000\n",
      "[584]\teval-aucpr:0.80609\ttrain-aucpr:1.00000\n",
      "[585]\teval-aucpr:0.80602\ttrain-aucpr:1.00000\n",
      "[586]\teval-aucpr:0.80586\ttrain-aucpr:1.00000\n",
      "[587]\teval-aucpr:0.80582\ttrain-aucpr:1.00000\n",
      "[588]\teval-aucpr:0.80588\ttrain-aucpr:1.00000\n",
      "[589]\teval-aucpr:0.80601\ttrain-aucpr:1.00000\n",
      "[590]\teval-aucpr:0.80610\ttrain-aucpr:1.00000\n",
      "[591]\teval-aucpr:0.80595\ttrain-aucpr:1.00000\n",
      "[592]\teval-aucpr:0.80598\ttrain-aucpr:1.00000\n",
      "[593]\teval-aucpr:0.80589\ttrain-aucpr:1.00000\n",
      "[594]\teval-aucpr:0.80591\ttrain-aucpr:1.00000\n",
      "[595]\teval-aucpr:0.80585\ttrain-aucpr:1.00000\n",
      "[596]\teval-aucpr:0.80583\ttrain-aucpr:1.00000\n",
      "[597]\teval-aucpr:0.80593\ttrain-aucpr:1.00000\n",
      "[598]\teval-aucpr:0.80590\ttrain-aucpr:1.00000\n",
      "[599]\teval-aucpr:0.80598\ttrain-aucpr:1.00000\n",
      "[600]\teval-aucpr:0.80593\ttrain-aucpr:1.00000\n",
      "[601]\teval-aucpr:0.80592\ttrain-aucpr:1.00000\n",
      "[602]\teval-aucpr:0.80592\ttrain-aucpr:1.00000\n",
      "[603]\teval-aucpr:0.80599\ttrain-aucpr:1.00000\n",
      "[604]\teval-aucpr:0.80603\ttrain-aucpr:1.00000\n",
      "[605]\teval-aucpr:0.80603\ttrain-aucpr:1.00000\n",
      "[606]\teval-aucpr:0.80604\ttrain-aucpr:1.00000\n",
      "[607]\teval-aucpr:0.80599\ttrain-aucpr:1.00000\n",
      "[608]\teval-aucpr:0.80610\ttrain-aucpr:1.00000\n",
      "[609]\teval-aucpr:0.80612\ttrain-aucpr:1.00000\n",
      "[610]\teval-aucpr:0.80611\ttrain-aucpr:1.00000\n",
      "[611]\teval-aucpr:0.80604\ttrain-aucpr:1.00000\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model with the best hyperparameter\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': round(params['eta'], 1),\n",
    "    'max_depth': round(params['max_depth']),\n",
    "    'gamma': round(params['gamma']),\n",
    "    'eval_metric': 'aucpr',\n",
    "}\n",
    "\n",
    "# Create a list of xgb.DMatrix\n",
    "watch_list = [\n",
    "    (test_xgb_matrix, 'eval'),\n",
    "    (training_xgb_matrix, 'train')\n",
    "]\n",
    "\n",
    "# Train the model with the selected hyperparameters\n",
    "xgb_model = xgb.train(params,\n",
    "                      training_xgb_matrix,\n",
    "                      num_boost_round=999,\n",
    "                      evals=watch_list,\n",
    "                      early_stopping_rounds=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(xgb_model, open(\"model/xgb_model.pkl\", \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def classify_type(y_pred, y_label):\n",
    "    rs = 'TP' if y_pred == 1 and y_label == 1 else 'FP' if y_pred == 1 and y_label == 0 else 'TN' if y_pred == 0 and y_label == 0 else 'FN'\n",
    "    return rs\n",
    "\n",
    "def evaluation(threshold):\n",
    "    test_evaluation = test.copy()\n",
    "    predictions = xgb_model.predict(test_xgb_matrix)\n",
    "    test_evaluation['label'] = test_evaluation.apply(lambda x: 0 if x['salary'] == \"<=50k\" else 1, axis=1)\n",
    "    test_evaluation['predicted_score'] = predictions\n",
    "    test_evaluation['predicted_label'] = test_evaluation.apply(lambda x: 1 if x['predicted_score'] >= threshold else 0, axis = 1)\n",
    "    test_evaluation['type'] = test_evaluation.apply(lambda x: classify_type(x['predicted_label'], x['label']), axis = 1)\n",
    "    y_predict = test_evaluation['predicted_label'].tolist()\n",
    "    precision, recall, fscore, support = score(y_test, y_predict)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "    return round(recall[1], 2), round(precision[1], 2), round(fscore[1], 2), round(accuracy, 2), y_test, y_predict, support"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Get the evaluation result\n",
    "threshold = 0.5\n",
    "recall, precision, fscore, accuracy, y_test, y_predict, support = evaluation(threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.64\n",
      "precision: 0.75\n",
      "fscore: 0.69\n",
      "support: [4905 1603]\n",
      "accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation result\n",
    "print('recall: {}' . format(recall))\n",
    "print('precision: {}' .format(precision))\n",
    "print('fscore: {}' .format(fscore))\n",
    "print('support: {}' .format(support))\n",
    "print('accuracy: {}' .format(accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      4905\n",
      "           1       0.75      0.64      0.69      1603\n",
      "\n",
      "    accuracy                           0.86      6508\n",
      "   macro avg       0.82      0.78      0.80      6508\n",
      "weighted avg       0.85      0.86      0.85      6508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report result\n",
    "print(classification_report(y_test, y_predict, target_names=['0', '1']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "  salary  person_count\n0  <=50K          4905\n1   >50K          1603",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>salary</th>\n      <th>person_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;=50K</td>\n      <td>4905</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&gt;50K</td>\n      <td>1603</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the distribution of the salary\n",
    "test.groupby(['salary']).agg(person_count=(\"salary\", \"count\")).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def compute_model_metrics(y, preds):\n",
    "    fscore = f1_score(y, preds, zero_division=1)\n",
    "    precision = precision_score(y, preds, zero_division=1)\n",
    "    recall = recall_score(y, preds, zero_division=1)\n",
    "    return precision, recall, fscore"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def evaluation(data, predictions, y_test_threshold):\n",
    "    data['label'] = y_test\n",
    "    data['predicted_score'] = predictions\n",
    "    data['predicted_label'] = data.apply(lambda x: 1 if x['predicted_score'] >= threshold else 0, axis = 1)\n",
    "    data['type'] = data.apply(lambda x: classify_type(x['predicted_label'], x['label']), axis = 1)\n",
    "    y_predict = data['predicted_label'].tolist()\n",
    "    precision, recall, fscore, support = score(y_test, y_predict)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    cl_report = classification_report(y_test, data['predicted_label'].values, target_names=['0', '1'])\n",
    "    #logging.info(f\"Classification report:\\n{cl_report}\")\n",
    "\n",
    "    return round(recall[1], 2), round(precision[1], 2), \\\n",
    "           round(fscore[1], 2), round(accuracy, 2), y_test, y_predict, data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def compute_slices(df, feature, y, preds, threshold):\n",
    "    slice_options = df[feature].unique().tolist()\n",
    "    perf_df = pd.DataFrame(index=slice_options, columns=['feature', 'n_samples', 'precision', 'recall', 'fscore'])\n",
    "    for option in slice_options:\n",
    "        slice_mask = df[feature]==option\n",
    "\n",
    "        slice_y = y[slice_mask]\n",
    "        slice_preds = preds[slice_mask]\n",
    "        precision, recall, fscore = compute_model_metrics(slice_y, slice_preds)\n",
    "\n",
    "        perf_df.loc[option, 'feature'] = feature\n",
    "        perf_df.loc[option, 'n_samples'] = len(slice_y)\n",
    "        perf_df.loc[option, 'precision'] = precision\n",
    "        perf_df.loc[option, 'recall'] = recall\n",
    "        perf_df.loc[option, 'fscore'] = fscore\n",
    "\n",
    "    # reorder columns in performance dataframe\n",
    "    perf_df.reset_index(names='feature value', inplace=True)\n",
    "    colList = list(perf_df.columns)\n",
    "    colList[0], colList[1] =  colList[1], colList[0]\n",
    "    perf_df = perf_df[colList]\n",
    "    return perf_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "preds = xgb_model.predict(test_xgb_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, ..., 0, 0, 1])"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_predict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "threshold = 0.50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass\n",
      "education\n",
      "marital-status\n",
      "occupation\n",
      "relationship\n",
      "race\n",
      "sex\n",
      "native-country\n"
     ]
    }
   ],
   "source": [
    "for feature in enumerate(categorical_features):\n",
    "    print(feature[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "for feature in enumerate(categorical_features):\n",
    "    performance_df = compute_slices(test, feature[1], y_test, np.array(y_predict), threshold)\n",
    "    if feature[0] == 0:\n",
    "        performance_df.to_csv(\"slice_pred.csv\",  mode='a', index=False)\n",
    "    else:\n",
    "        performance_df.to_csv(\"slice_pred.csv\",  mode='a', header=False, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1] == X_test.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exists\n"
     ]
    }
   ],
   "source": [
    "# Test the model exist or not\n",
    "model_path = \"./model/xgb_models.pkl\"\n",
    "if os.path.isfile(model_path):\n",
    "    model = pickle.load(open(model_path, 'rb'))\n",
    "else:\n",
    "    print(\"File does not exists\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jumet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "print(home_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jumet/DE/Udacity/Cencus_Project/Census_Bureau_Prediction/starter\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "print(current_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jumet/DE/Udacity/Cencus_Project/Census_Bureau_Prediction/starter\n"
     ]
    }
   ],
   "source": [
    "project_dir = os.path.dirname(os.path.abspath(\"model.py\"))\n",
    "print(project_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/eda\n"
     ]
    }
   ],
   "source": [
    "absolute_path = '/eda/'\n",
    "absolute_dir = os.path.dirname(absolute_path)\n",
    "print(absolute_dir)  # Output: '/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}